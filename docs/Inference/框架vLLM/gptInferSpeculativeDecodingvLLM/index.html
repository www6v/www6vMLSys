<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="


  Speculating with a draft model[1]
  #

from vllm import LLM, SamplingParams

prompts = [
    &#34;The future of AI is&#34;,
]
sampling_params = SamplingParams(temperature=0.8, top_p=0.95)

llm = LLM(
    model=&#34;facebook/opt-6.7b&#34;, # verify 小模型
    tensor_parallel_size=1,
    speculative_model=&#34;facebook/opt-125m&#34;,    # draft 小模型
    num_speculative_tokens=5, # 一次生成5个token 
)
outputs = llm.generate(prompts, sampling_params)

for output in outputs:
    prompt = output.prompt
    generated_text = output.outputs[0].text
    print(f&#34;Prompt: {prompt!r}, Generated text: {generated_text!r}&#34;)
python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --port 8000 \
       --model facebook/opt-6.7b \
       --seed 42 -tp 1 \
       --speculative_model facebook/opt-125m \
       --use-v2-block-manager \
       --num_speculative_tokens 5 \
       --gpu_memory_utilization 0.8 \


Small LM">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://www6v.github.io/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInferSpeculativeDecodingvLLM/">
  <meta property="og:site_name" content="MLSys">
  <meta property="og:title" content="(实战)[vLLM]投机解码 &#43;">
  <meta property="og:description" content="Speculating with a draft model[1] # from vllm import LLM, SamplingParams prompts = [ &#34;The future of AI is&#34;, ] sampling_params = SamplingParams(temperature=0.8, top_p=0.95) llm = LLM( model=&#34;facebook/opt-6.7b&#34;, # verify 小模型 tensor_parallel_size=1, speculative_model=&#34;facebook/opt-125m&#34;, # draft 小模型 num_speculative_tokens=5, # 一次生成5个token ) outputs = llm.generate(prompts, sampling_params) for output in outputs: prompt = output.prompt generated_text = output.outputs[0].text print(f&#34;Prompt: {prompt!r}, Generated text: {generated_text!r}&#34;) python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --port 8000 \ --model facebook/opt-6.7b \ --seed 42 -tp 1 \ --speculative_model facebook/opt-125m \ --use-v2-block-manager \ --num_speculative_tokens 5 \ --gpu_memory_utilization 0.8 \ Small LM">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="website">
<title>(实战)[vLLM]投机解码 &#43; | MLSys</title>
<link rel="icon" href="/www6vMLSys/favicon.png" >
<link rel="manifest" href="/www6vMLSys/manifest.json">
<link rel="canonical" href="https://www6v.github.io/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInferSpeculativeDecodingvLLM/">
<link rel="stylesheet" href="/www6vMLSys/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/www6vMLSys/fuse.min.js"></script>
  <script defer src="/www6vMLSys/en.search.min.8a48a87ac04e77b03adebe35be8d1a27a08c5237e42759e78c9cff823366155b.js" integrity="sha256-ikioesBOd7A63r41vo0aJ6CMUjfkJ1nnjJz/gjNmFVs=" crossorigin="anonymous"></script>
<link rel="alternate" type="application/rss+xml" href="https://www6v.github.io/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInferSpeculativeDecodingvLLM/index.xml" title="MLSys" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/www6vMLSys/"><span>MLSys</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>















  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-bf23c006d2140684cc90ded82ec74653" class="toggle" checked />
    <label for="section-bf23c006d2140684cc90ded82ec74653" class="flex justify-between">
      <a role="button" class="">Inference</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-e2782e122236beb02b611a4b4376c5ba" class="toggle"  />
    <label for="section-e2782e122236beb02b611a4b4376c5ba" class="flex justify-between">
      <a role="button" class="">框架</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6/gptInferFramework/" class="">(原理)推理-框架</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6/gptInferFrameworkPractice/" class="">(实战)推理-lmdeploy</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6/gptInferTensorRT/" class="">(原理|实战) TensorRT-LLM &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6/gptInferRay/" class="">(原理)推理 Ray</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6/gptInferRayPractice/" class="">(实战)推理 Ray</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-280e12f1588c5189fc8326fb4998fa2a" class="toggle" checked />
    <label for="section-280e12f1588c5189fc8326fb4998fa2a" class="flex justify-between">
      <a role="button" class="">框架vLLM</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInfervLLM/" class="">(原理) vLLM  &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInfervLLMPractice/" class="">(实战) vLLM &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInferSpeculativeDecodingvLLM/" class="active">(实战)[vLLM]投机解码 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInferKVCacheRadixAttention/" class="">(原理|实战) [vLLM]Prefix Cache &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInfervLLMCode/" class="">(实现)[vLLM]整体架构 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInfervLLMDist/" class="">(实现)[vLLM]分布式 *</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInfervLLMPD/" class="">(实现)[vLLM]PD分离 *</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInfervLLMSpeculativeDecode/" class="">(实现)[vLLM]投机解码 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInfervLLMPrefixCaching/" class="">(实现)[vLLM]Prefix Caching &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference/%E6%A1%86%E6%9E%B6vLLM/gptInfervLLMv1/" class="">(实现)[vLLM]V1 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-d659e6fde8f172d5e6d65a0b2bc79031" class="toggle"  />
    <label for="section-d659e6fde8f172d5e6d65a0b2bc79031" class="flex justify-between">
      <a role="button" class="">Inference 优化</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8cc4904ea51a1aff793d6755622ea54b" class="toggle"  />
    <label for="section-8cc4904ea51a1aff793d6755622ea54b" class="flex justify-between">
      <a role="button" class="">Overview</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/Overview/gptInference/" class="">(总结)推理优化</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/Overview/gptInferenceSurvey/" class="">(综述)推理优化 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/Overview/gptInferenceSurvey1/" class="">(综述)推理优化 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-75fffd45c4e3af9b253513bcf99a1e7e" class="toggle"  />
    <label for="section-75fffd45c4e3af9b253513bcf99a1e7e" class="flex justify-between">
      <a role="button" class="">系统层优化</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-2c31e36f5b0e9f84d75738e603bcdfd3" class="toggle"  />
    <label for="section-2c31e36f5b0e9f84d75738e603bcdfd3" class="flex justify-between">
      <a role="button" class="">FlashAttention</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/FlashAttention/gptFlashAttention/" class="">(原理)Flash Attention &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/FlashAttention/gptInferFlashAttention2/" class="">(原理)FlashAttention2 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/FlashAttention/gptInferFlashDecoding/" class="">(原理)Flash Decoding &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-903dc4762e53fc23899b8b41e24d4e3d" class="toggle"  />
    <label for="section-903dc4762e53fc23899b8b41e24d4e3d" class="flex justify-between">
      <a role="button" class="">SpeculativeDecoding</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/SpeculativeDecoding/gptInferSpeculativeDecoding/" class="">Speculative Decoding &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/SpeculativeDecoding/gptInferSpeculativeDecodingSurvey/" class="">(Survey)Speculative Decoding &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/SpeculativeDecoding/gptInferMedusa/" class="">(原理|实现)Medusa &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/SpeculativeDecoding/gptInferEagle/" class="">EAGLE &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/SpeculativeDecoding/gptInferSpecInfer/" class="">SpecInfer &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9c3aeee5bee9d8a45b6959715db1f460" class="toggle"  />
    <label for="section-9c3aeee5bee9d8a45b6959715db1f460" class="flex justify-between">
      <a role="button" class="">KVCache</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/KVCache/gptInferKVCache/" class="">(原理|实现) KV Cache &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/KVCache/gptInferKVCacheOptimize/" class="">(原理)KV Cache 优化 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-a0d66f65a2c7b4e05694f79579d1f686" class="toggle"  />
    <label for="section-a0d66f65a2c7b4e05694f79579d1f686" class="flex justify-between">
      <a role="button" class="">Compress</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/KVCache/Compress/gptInferKVCacheQuantization/" class="">(原理)KV Cache 量化 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cc89fec5cef17da80426c3ab29dc55f2" class="toggle"  />
    <label for="section-cc89fec5cef17da80426c3ab29dc55f2" class="flex justify-between">
      <a role="button" class="">Batch</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/Batch/gptInferContinuousBatching/" class="">Continuous Batching &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/Batch/gptInferChunkedPrefill/" class="">Chunked Prefill &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-a86001c551f91c9d6742692d85235ce9" class="toggle"  />
    <label for="section-a86001c551f91c9d6742692d85235ce9" class="flex justify-between">
      <a role="button" class="">PD 分离</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/PD-%E5%88%86%E7%A6%BB/gptInferDistServe/" class="">DistServe &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/PD-%E5%88%86%E7%A6%BB/gptInferMooncake/" class="">(原理|实现)Mooncake &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96/PD-%E5%88%86%E7%A6%BB/gptInferLlumnix/" class="">(原理)Llumnix &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-0a8aa3616751d94d876ab5a7638dfee2" class="toggle"  />
    <label for="section-0a8aa3616751d94d876ab5a7638dfee2" class="flex justify-between">
      <a role="button" class="">模型层优化</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-5a6462bfaadf7adfe8b66d09bc58303b" class="toggle"  />
    <label for="section-5a6462bfaadf7adfe8b66d09bc58303b" class="flex justify-between">
      <a role="button" class="">量化</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-2d87a22f91be75b78e6616958283b668" class="toggle"  />
    <label for="section-2d87a22f91be75b78e6616958283b668" class="flex justify-between">
      <a role="button" class="">Overview</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E6%A8%A1%E5%9E%8B%E5%B1%82%E4%BC%98%E5%8C%96/%E9%87%8F%E5%8C%96/Overview/gptQuantizationSurvey/" class="">(Survey)Quantization &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E6%A8%A1%E5%9E%8B%E5%B1%82%E4%BC%98%E5%8C%96/%E9%87%8F%E5%8C%96/Overview/gptQuantization/" class="">(原理)量化 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-88d52cf49c9a5295f0c154e14ccc03a5" class="toggle"  />
    <label for="section-88d52cf49c9a5295f0c154e14ccc03a5" class="flex justify-between">
      <a role="button" class="">PTQ</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E6%A8%A1%E5%9E%8B%E5%B1%82%E4%BC%98%E5%8C%96/%E9%87%8F%E5%8C%96/PTQ/gptQuantizationWeight/" class="">(原理)PTQ-Weight Only &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-359a9d256fc5cc0b6a903de93454a7d5" class="toggle"  />
    <label for="section-359a9d256fc5cc0b6a903de93454a7d5" class="flex justify-between">
      <a role="button" class="">Weight Only</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E6%A8%A1%E5%9E%8B%E5%B1%82%E4%BC%98%E5%8C%96/%E9%87%8F%E5%8C%96/PTQ/Weight-Only/gptQuantizationGPTQ/" class="">(原理|实战|实现)GPTQ &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E6%A8%A1%E5%9E%8B%E5%B1%82%E4%BC%98%E5%8C%96/%E9%87%8F%E5%8C%96/PTQ/Weight-Only/gptQuantizationAWQ/" class="">(原理|实战)AWQ &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-80f1cfdbb0d11740a87708737d9705d1" class="toggle"  />
    <label for="section-80f1cfdbb0d11740a87708737d9705d1" class="flex justify-between">
      <a role="button" class="">Weight&amp;Activation</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E6%A8%A1%E5%9E%8B%E5%B1%82%E4%BC%98%E5%8C%96/%E9%87%8F%E5%8C%96/PTQ/WeightActivation/gptQuantizationInt8/gptQuantizationInt8/" class="">(原理|实战)LLM.int8() &#43;</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E6%A8%A1%E5%9E%8B%E5%B1%82%E4%BC%98%E5%8C%96/%E9%87%8F%E5%8C%96/PTQ/WeightActivation/gptQuantizationSmoothQuant/gptQuantizationSmoothQuant/" class="">(原理)SmoothQuant &#43;</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E6%A8%A1%E5%9E%8B%E5%B1%82%E4%BC%98%E5%8C%96/%E9%87%8F%E5%8C%96/PTQ/WeightActivation/gptQuantizationFP8/gptQuantizationFP8/" class="">(原理)FP8 &#43;</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-0fae359329dcf38fe41928a875455a3a" class="toggle"  />
    <label for="section-0fae359329dcf38fe41928a875455a3a" class="flex justify-between">
      <a role="button" class="">Practice</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E6%A8%A1%E5%9E%8B%E5%B1%82%E4%BC%98%E5%8C%96/%E9%87%8F%E5%8C%96/Practice/gptQuantizationPractice/" class="">(实战)量化 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1bda5152ea8335d4cdc6a16fa79ec8a2" class="toggle"  />
    <label for="section-1bda5152ea8335d4cdc6a16fa79ec8a2" class="flex justify-between">
      <a role="button" class="">Sparse Attention</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E6%A8%A1%E5%9E%8B%E5%B1%82%E4%BC%98%E5%8C%96/Sparse-Attention/gptInferKVCacheStreamingLLM/" class="">(原理)Streaming LLM &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-92274cd592f961ae92a826acd4a198e7" class="toggle"  />
    <label for="section-92274cd592f961ae92a826acd4a198e7" class="flex justify-between">
      <a role="button" class="">其他</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Inference-Opt/%E5%85%B6%E4%BB%96/gptTemperature/" class="">推理常见参数 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-f4030e06a7cd0b4d4f01c69f804511e3" class="toggle"  />
    <label for="section-f4030e06a7cd0b4d4f01c69f804511e3" class="flex justify-between">
      <a role="button" class="">Training</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-a3302ad31d47b6b33edaefb16b9595c8" class="toggle"  />
    <label for="section-a3302ad31d47b6b33edaefb16b9595c8" class="flex justify-between">
      <a role="button" class="">分布式</a>
    </label>
  

          
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-ca35777dc3dc1df2cd1c182701911ffb" class="toggle"  />
    <label for="section-ca35777dc3dc1df2cd1c182701911ffb" class="flex justify-between">
      <a role="button" class="">Overview</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Training/%E5%88%86%E5%B8%83%E5%BC%8F/Overview/TrainParallelism/" class="">(原理)分布式训练 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-ae4385c3230d5a72d0fd739cfe337330" class="toggle"  />
    <label for="section-ae4385c3230d5a72d0fd739cfe337330" class="flex justify-between">
      <a role="button" class="">DP</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Training/%E5%88%86%E5%B8%83%E5%BC%8F/DP/TrainZeroDeepspeed/" class="">(原理) Deepspeed Zero &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Training/%E5%88%86%E5%B8%83%E5%BC%8F/DP/TrainDistributedPractice/" class="">(实战)DeepSpeed Training &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Training/%E5%88%86%E5%B8%83%E5%BC%8F/DP/TrainDDP/" class="">(原理|实战)DDP &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Training/%E5%88%86%E5%B8%83%E5%BC%8F/DP/TrainFSDP/" class="">(原理|实战)FSDP &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-0cfa5a342351431197e06859d2a0b5dd" class="toggle"  />
    <label for="section-0cfa5a342351431197e06859d2a0b5dd" class="flex justify-between">
      <a role="button" class="">TP</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Training/%E5%88%86%E5%B8%83%E5%BC%8F/TP/TrainTensorParallelism/" class="">(原理)张量并行(TP) &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-bf4278f3920999fc3bb13908e22d34bb" class="toggle"  />
    <label for="section-bf4278f3920999fc3bb13908e22d34bb" class="flex justify-between">
      <a role="button" class="">PP</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Training/%E5%88%86%E5%B8%83%E5%BC%8F/PP/TrainPipelineParallelism/" class="">(原理|实战)流水线并行(PP) &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-30fd02881b0903fc1d9b6c52304de566" class="toggle"  />
    <label for="section-30fd02881b0903fc1d9b6c52304de566" class="flex justify-between">
      <a role="button" class="">混合并行</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Training/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%B7%B7%E5%90%88%E5%B9%B6%E8%A1%8C/TrainMegatron/" class="">(原理)Megatron &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Training/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%B7%B7%E5%90%88%E5%B9%B6%E8%A1%8C/TrainHybridParallel/" class="">(原理)混合并行 &#43;</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-25028652b0e6469d4e603a946ea402c4" class="toggle"  />
    <label for="section-25028652b0e6469d4e603a946ea402c4" class="flex justify-between">
      <a role="button" class="">低精度</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Training/%E4%BD%8E%E7%B2%BE%E5%BA%A6/LowPrecision/gptLowPrecision/" class="">低精度训练 &#43;</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/Training/%E4%BD%8E%E7%B2%BE%E5%BA%A6/Precision/gptPrecision/" class="">(原理|实战)混合精度 &#43;</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-4c59ddc3d219d63b3dde79b574842e09" class="toggle"  />
    <label for="section-4c59ddc3d219d63b3dde79b574842e09" class="flex justify-between">
      <a role="button" class="">LLMOps</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7ebdcb9a1f5f42cca0e13037c0b12b5d" class="toggle"  />
    <label for="section-7ebdcb9a1f5f42cca0e13037c0b12b5d" class="flex justify-between">
      <a role="button" class="">MaaS</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/MaaS/gptMaaSMonitor/" class="">MaaS 监控</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/MaaS/gptLLMOpsPaaS/" class="">LLM PaaS</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/LLamaFactory/" class="">LLama-Factory</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/GPUComputing/" class="">显存估算</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/LLMOps/" class="">LLMOps</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9484c8ef5479ebf1810697d279568858" class="toggle"  />
    <label for="section-9484c8ef5479ebf1810697d279568858" class="flex justify-between">
      <a role="button" class="">GPU</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/GPU/GPUk8s/" class="">(实战)K8s部署GPU</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/GPU/GPUMetrics/" class="">GPU 指标&amp;监控</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/GPU/GPU/" class="">GPU 算力平台</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-542e0883d2790694810f81c484e2ab13" class="toggle"  />
    <label for="section-542e0883d2790694810f81c484e2ab13" class="flex justify-between">
      <a role="button" class="">AI平台</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/AI%E5%B9%B3%E5%8F%B0/aiPlatform/" class="">(原理)AI平台</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/AI%E5%B9%B3%E5%8F%B0/aiObserve/" class="">(阿里)AI 应用观测</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8f868c3c013a787783e65df936258f6a" class="toggle"  />
    <label for="section-8f868c3c013a787783e65df936258f6a" class="flex justify-between">
      <a role="button" class="">AI网关</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/AI%E5%B9%B3%E5%8F%B0/AI%E7%BD%91%E5%85%B3/LiteLLM/" class="">(实现)LiteLLM</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vMLSys/docs/LLMOps/AI%E5%B9%B3%E5%8F%B0/AI%E7%BD%91%E5%85%B3/aiGateway/" class="">(阿里) AI 网关</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>














</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/www6vMLSys/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>(实战)[vLLM]投机解码 &#43;</h3>

  <label for="toc-control">
    
    <img src="/www6vMLSys/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#speculating-with-a-draft-model"><strong>Speculating with a draft model[1]</strong></a></li>
    <li><a href="#speculating-by-matching-n-grams-in-the-prompt"><strong>Speculating by matching n-grams in the prompt[1,2]</strong></a></li>
    <li><a href="#speculating-using-mlp-speculators"><strong>Speculating using MLP speculators[1]</strong></a></li>
    <li><a href="#参考">参考</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><p></p>
<!-- more -->
<h1 id="speculating-with-a-draft-model">
  <strong>Speculating with a draft model[1]</strong>
  <a class="anchor" href="#speculating-with-a-draft-model">#</a>
</h1>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> vllm <span style="color:#f92672">import</span> LLM, SamplingParams
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>prompts <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;The future of AI is&#34;</span>,
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>sampling_params <span style="color:#f92672">=</span> SamplingParams(temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>, top_p<span style="color:#f92672">=</span><span style="color:#ae81ff">0.95</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>llm <span style="color:#f92672">=</span> LLM(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;facebook/opt-6.7b&#34;</span>, <span style="color:#75715e"># verify 小模型</span>
</span></span><span style="display:flex;"><span>    tensor_parallel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>    speculative_model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;facebook/opt-125m&#34;</span>,    <span style="color:#75715e"># draft 小模型</span>
</span></span><span style="display:flex;"><span>    num_speculative_tokens<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, <span style="color:#75715e"># 一次生成5个token </span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>outputs <span style="color:#f92672">=</span> llm<span style="color:#f92672">.</span>generate(prompts, sampling_params)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> output <span style="color:#f92672">in</span> outputs:
</span></span><span style="display:flex;"><span>    prompt <span style="color:#f92672">=</span> output<span style="color:#f92672">.</span>prompt
</span></span><span style="display:flex;"><span>    generated_text <span style="color:#f92672">=</span> output<span style="color:#f92672">.</span>outputs[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>text
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Prompt: </span><span style="color:#e6db74">{</span>prompt<span style="color:#e6db74">!r}</span><span style="color:#e6db74">, Generated text: </span><span style="color:#e6db74">{</span>generated_text<span style="color:#e6db74">!r}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-powershell" data-lang="powershell"><span style="display:flex;"><span>python -m vllm.entrypoints.openai.api_server --host <span style="color:#ae81ff">0.0</span>.0.0 --port <span style="color:#ae81ff">8000</span> \
</span></span><span style="display:flex;"><span>       --model facebook/opt-<span style="color:#ae81ff">6</span>.7b \
</span></span><span style="display:flex;"><span>       --seed <span style="color:#ae81ff">42</span> -tp <span style="color:#ae81ff">1</span> \
</span></span><span style="display:flex;"><span>       --speculative_model facebook/opt-<span style="color:#ae81ff">125m</span> \
</span></span><span style="display:flex;"><span>       --use-v2-block-manager \
</span></span><span style="display:flex;"><span>       --num_speculative_tokens <span style="color:#ae81ff">5</span> \
</span></span><span style="display:flex;"><span>       --gpu_memory_utilization <span style="color:#ae81ff">0.8</span> \
</span></span></code></pre></div><ul>
<li>
<p>Small LM</p>
<p>DistillSpec</p>
</li>
</ul>
<h1 id="speculating-by-matching-n-grams-in-the-prompt">
  <strong>Speculating by matching n-grams in the prompt[1,2]</strong>
  <a class="anchor" href="#speculating-by-matching-n-grams-in-the-prompt">#</a>
</h1>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-powershell" data-lang="powershell"><span style="display:flex;"><span>from vllm import LLM, SamplingParams
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>prompts = [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;The future of AI is&#34;</span>,
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>sampling_params = SamplingParams(temperature=<span style="color:#ae81ff">0.8</span>, top_p=<span style="color:#ae81ff">0.95</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>llm = LLM(
</span></span><span style="display:flex;"><span>    model=<span style="color:#e6db74">&#34;facebook/opt-6.7b&#34;</span>,
</span></span><span style="display:flex;"><span>    tensor_parallel_size=<span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>    speculative_model=<span style="color:#e6db74">&#34;[ngram]&#34;</span>, <span style="color:#75715e"># ngram</span>
</span></span><span style="display:flex;"><span>    num_speculative_tokens=<span style="color:#ae81ff">5</span>,   <span style="color:#75715e"># 一次生成5个token</span>
</span></span><span style="display:flex;"><span>    ngram_prompt_lookup_max=<span style="color:#ae81ff">4</span>,  
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>outputs = llm.generate(prompts, sampling_params)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> output <span style="color:#66d9ef">in</span> outputs<span style="color:#960050;background-color:#1e0010">:</span>
</span></span><span style="display:flex;"><span>    prompt = output.prompt
</span></span><span style="display:flex;"><span>    generated_text = output.outputs[<span style="color:#ae81ff">0</span>].text
</span></span><span style="display:flex;"><span>    print(f<span style="color:#e6db74">&#34;Prompt: {prompt!r}, Generated text: {generated_text!r}&#34;</span>)
</span></span></code></pre></div><ul>
<li>lookahead</li>
</ul>
<h1 id="speculating-using-mlp-speculators">
  <strong>Speculating using MLP speculators[1]</strong>
  <a class="anchor" href="#speculating-using-mlp-speculators">#</a>
</h1>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-powershell" data-lang="powershell"><span style="display:flex;"><span>from vllm import LLM, SamplingParams
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>prompts = [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;The future of AI is&#34;</span>,
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>sampling_params = SamplingParams(temperature=<span style="color:#ae81ff">0.8</span>, top_p=<span style="color:#ae81ff">0.95</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>llm = LLM(
</span></span><span style="display:flex;"><span>    model=<span style="color:#e6db74">&#34;meta-llama/Meta-Llama-3.1-70B-Instruct&#34;</span>,
</span></span><span style="display:flex;"><span>    tensor_parallel_size=<span style="color:#ae81ff">4</span>,
</span></span><span style="display:flex;"><span>    speculative_model=<span style="color:#e6db74">&#34;ibm-fms/llama3-70b-accelerator&#34;</span>,
</span></span><span style="display:flex;"><span>    speculative_draft_tensor_parallel_size=<span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>outputs = llm.generate(prompts, sampling_params)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> output <span style="color:#66d9ef">in</span> outputs<span style="color:#960050;background-color:#1e0010">:</span>
</span></span><span style="display:flex;"><span>    prompt = output.prompt
</span></span><span style="display:flex;"><span>    generated_text = output.outputs[<span style="color:#ae81ff">0</span>].text
</span></span><span style="display:flex;"><span>    print(f<span style="color:#e6db74">&#34;Prompt: {prompt!r}, Generated text: {generated_text!r}&#34;</span>)
</span></span></code></pre></div><ul>
<li>Medusa</li>
</ul>
<h1 id="参考">
  参考
  <a class="anchor" href="#%e5%8f%82%e8%80%83">#</a>
</h1>
<ol>
<li>
<p><a href="https://docs.vllm.ai/en/stable/models/spec_decode.html">Speculative decoding in vLLM</a>  3种类型</p>
</li>
<li>
<p><a href="https://docs.google.com/document/d/1Z9TvqzzBPnh5WHcRwjvK2UEeFeq5zMZb5mFE8jR0HCs/edit#heading=h.1fjfb0donq5a">What is Lookahead Scheduling in vLLM?</a></p>
</li>
</ol>
<p>1xx. <a href="https://www.youtube.com/watch?v=9wNAgpX6z_4">A Hacker’s Guide to Speculative Decoding in vLLM</a> v ***</p>
<p><a href="https://docs.google.com/presentation/d/1p1xE-EbSAnXpTSiSI0gmy_wdwxN5XaULO3AnCWWoRe4/edit#slide=id.p">A Hacker’s Guide to Speculative Decoding in vLLM</a>  pdf</p>
<p>1xx. <a href="https://docs.google.com/document/d/1T-JaS2T1NRfdP51qzqpyakoCXxSXTtORppiwaj5asxA/edit#heading=h.kk7dq05lc6q8">Optimizing attention for spec decode can reduce latency / increase throughput</a></p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#speculating-with-a-draft-model"><strong>Speculating with a draft model[1]</strong></a></li>
    <li><a href="#speculating-by-matching-n-grams-in-the-prompt"><strong>Speculating by matching n-grams in the prompt[1,2]</strong></a></li>
    <li><a href="#speculating-using-mlp-speculators"><strong>Speculating using MLP speculators[1]</strong></a></li>
    <li><a href="#参考">参考</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












